{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11947840,"sourceType":"datasetVersion","datasetId":7507953}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\n\nmodel_name = \"ai-forever/mGPT\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")","metadata":{"_uuid":"b624d53b-10f3-4dd7-b364-73c4c6f65782","_cell_guid":"4f12dd70-797e-43df-8161-340448776bfb","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-25T15:38:04.264799Z","iopub.execute_input":"2025-05-25T15:38:04.265211Z","iopub.status.idle":"2025-05-25T15:38:08.278328Z","shell.execute_reply.started":"2025-05-25T15:38:04.265189Z","shell.execute_reply":"2025-05-25T15:38:08.277770Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from peft import get_peft_model, LoraConfig, TaskType\n\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=32,\n    target_modules=[\"c_attn\"], \n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=TaskType.CAUSAL_LM\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"_uuid":"5781ca93-dcb9-439b-915e-dc1dd1d4d33c","_cell_guid":"a6670cca-14ba-4a5e-b9af-42541c778bf8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-25T15:38:08.279434Z","iopub.execute_input":"2025-05-25T15:38:08.279653Z","iopub.status.idle":"2025-05-25T15:38:08.335328Z","shell.execute_reply.started":"2025-05-25T15:38:08.279636Z","shell.execute_reply":"2025-05-25T15:38:08.334721Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"trainable params: 1,572,864 || all params: 1,419,169,792 || trainable%: 0.1108\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"json\", data_files=\"/kaggle/input/ziare-romania/romania_dataset.json\")\n\ndef tokenize_function(examples):\n    texts = [f\"Title: {title}\\nContent: {content}\" for title, content in zip(examples[\"title\"], examples[\"content\"])]\n    \n    tokenized = tokenizer(\n        texts, \n        padding=\"max_length\", \n        truncation=True, \n        max_length=512,\n        return_tensors=\"pt\"\n    )\n\n    tokenized[\"labels\"] = tokenized[\"input_ids\"].clone()\n    \n    return tokenized\n\ntokenized_dataset = dataset.map(tokenize_function, batched=True)","metadata":{"_uuid":"8388cc4b-0369-43a0-9805-aa0927128d51","_cell_guid":"528f13f7-7afc-4648-af2f-a4bdd73db29f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-25T15:38:08.336016Z","iopub.execute_input":"2025-05-25T15:38:08.336252Z","iopub.status.idle":"2025-05-25T15:38:08.620135Z","shell.execute_reply.started":"2025-05-25T15:38:08.336228Z","shell.execute_reply":"2025-05-25T15:38:08.619576Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir=\"./mgpt-lora-finetuned\",\n    per_device_train_batch_size=4,\n    num_train_epochs=2,\n    save_strategy=\"steps\",\n    # save_steps=500,\n    logging_steps=100,\n    learning_rate=0.00001,\n    fp16=True,\n    report_to=\"none\"\n)","metadata":{"_uuid":"8deb56f7-11fc-4998-bda2-3378a5f5345a","_cell_guid":"a1833bf5-abb6-43d0-92c7-5f4e679f266c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-25T15:38:08.621387Z","iopub.execute_input":"2025-05-25T15:38:08.621643Z","iopub.status.idle":"2025-05-25T15:38:08.653720Z","shell.execute_reply.started":"2025-05-25T15:38:08.621625Z","shell.execute_reply":"2025-05-25T15:38:08.653179Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n)\n\ntrainer.train()","metadata":{"_uuid":"cadc1bbb-a36e-4ecd-a0e3-efe6ebdf82e3","_cell_guid":"6d4db7c6-be5f-4a45-99e1-42f7336830ef","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-25T15:38:08.654455Z","iopub.execute_input":"2025-05-25T15:38:08.654903Z","iopub.status.idle":"2025-05-25T15:38:10.584234Z","shell.execute_reply.started":"2025-05-25T15:38:08.654884Z","shell.execute_reply":"2025-05-25T15:38:10.583672Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 00:00, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1, training_loss=20.03041648864746, metrics={'train_runtime': 1.5016, 'train_samples_per_second': 1.715, 'train_steps_per_second': 0.666, 'total_flos': 14870636396544.0, 'train_loss': 20.03041648864746, 'epoch': 0.00015535187199005747})"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"model.save_pretrained(\"mgpt-lora-adapter\")\ntokenizer.save_pretrained(\"mgpt-lora-adapter\")","metadata":{"_uuid":"366491f6-8a98-48a1-b800-b28ad40d8d51","_cell_guid":"900bb9b3-f584-47a4-8248-4f7a9cef10d5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-25T15:38:10.584907Z","iopub.execute_input":"2025-05-25T15:38:10.585231Z","iopub.status.idle":"2025-05-25T15:38:10.890166Z","shell.execute_reply.started":"2025-05-25T15:38:10.585212Z","shell.execute_reply":"2025-05-25T15:38:10.889445Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"('mgpt-lora-adapter/tokenizer_config.json',\n 'mgpt-lora-adapter/special_tokens_map.json',\n 'mgpt-lora-adapter/vocab.json',\n 'mgpt-lora-adapter/merges.txt',\n 'mgpt-lora-adapter/added_tokens.json',\n 'mgpt-lora-adapter/tokenizer.json')"},"metadata":{}}],"execution_count":28}]}