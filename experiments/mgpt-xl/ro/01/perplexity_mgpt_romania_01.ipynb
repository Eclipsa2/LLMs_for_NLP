{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac6bb2d-5ce4-4d70-86d7-0be410d5d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch\n",
    "import json\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c51e3bc9-7682-4acd-b7e4-6c925fdac96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 2048\n",
    "adapter_path = \"mgpt-lora-adapter_romania_01\"\n",
    "tokenizer_path = adapter_path + '_tok'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "545d3f5b-e147-4aba-b88b-e87e9b4dec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "peft_config = PeftConfig.from_pretrained(adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "887509a7-e04b-4348-a7a1-0182c25f35f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be14d997-788b-48bc-8917-798eabd1cdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2LMHeadModel(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(100000, 2048)\n",
       "        (wpe): Embedding(2048, 2048)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-23): 24 x GPT2Block(\n",
       "            (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=6144, nx=2048)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=6144, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=2048, nx=2048)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D(nf=8192, nx=2048)\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=2048, nx=8192)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=100000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "model.to(\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "897d7044-6a3f-4d43-82b3-ab2532164fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_md = load_dataset(\"json\", data_files=\"moldova_dataset.json\")\n",
    "dataset_md = dataset_md['train'].train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "dataset_ro = load_dataset(\"json\", data_files=\"romania_dataset.json\")\n",
    "dataset_ro = dataset_ro['train'].train_test_split(test_size=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fee34da-14c6-41da-a937-e30723ede281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1274, 2305)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_md['test']), len(dataset_ro['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1d1d734-4ae7-4876-aabc-9e6e33d648d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_md = []\n",
    "title_ro = []\n",
    "\n",
    "content_md = []\n",
    "content_ro = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5f3704f-d7d5-49d7-bd09-c094bfb1aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model, tokenizer, text):\n",
    "    # print(text)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(model.device)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "    \n",
    "    neg_log_likelihood = outputs.loss\n",
    "    perplexity = math.exp(neg_log_likelihood.item())\n",
    "    \n",
    "    return perplexity, neg_log_likelihood.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edbf1859-fd8f-4e53-b153-0311bf16dce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Accident mortal, pe DN 56',\n",
       " 'text': 'Două persoane au decedat în urma unui accident rutier grav care a avut loc, în noaptea de joi spre vineri, pe DN 56 în județul Dolj, în afara localității Basarabi.\\n\\n”În noaptea de 23/24 martie a.c., ora 01.10 polițiștii Poliției Municipiului Calafat au fost sesizați cu privire la faptul că, pe D.N 56, în afara localității Basarabi, sensul de mers către Calafat, a avut loc un accident rutier.\\n\\nLa fața locului s-au deplasat polițiștii care au stabilit faptul că, un bărbat, de 63 de ani, cetățean turc, în timp ce conducea o autoutilitară pe D.N. 56, în afara localității Basarabi, din direcția Maglavit către Calafat, din cauze ce urmează a fi stabilite în urma cercetărilor, a intrat în coliziune cu un autocamion stationat pe partea carosabilă, fiind defect și semnalizat corespunzător. \\n\\n În urma evenimentului rutier, conducătorul auto de 63 de ani și o femeie, tot de 63 de ani, cetățean bulgar, pasager în autoutilitară, au decedat.\\n\\nÎn cauză, poliţiştii au întocmit un dosar penal sub aspectul săvârşirii infracțiunii de ucidere din culpă, cercetările fiind continuate pentru stabilirea împrejurărilor în care s-a produs accidentul. Sursa: craiovatv.ro'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ro['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3d0078e-fcd1-49ab-a9be-72e6ffebef76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2305 [00:00<?, ?it/s]`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "100%|██████████| 2305/2305 [01:00<00:00, 38.20it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(dataset_ro['test']):\n",
    "    # if row['title'] is None or row['title'] == '' or row['text'] is None or row['text'] == '':\n",
    "    #     print(row['content'])\n",
    "    #     continue\n",
    "    # print(row)\n",
    "    try:\n",
    "        perp, negloglike = compute_metrics(model, tokenizer, row['title'])\n",
    "        title_ro.append({'title': row['title'], 'perplexity': perp, 'neg_log_likelihood': negloglike})\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        perp, negloglike = compute_metrics(model, tokenizer, row['text'])\n",
    "        content_ro.append({'text': row['text'], 'perplexity': perp, 'neg_log_likelihood': negloglike})\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebe08925-2c66-44db-af00-ee43a68b4cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2305, 2276)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_ro), len(content_ro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ec43061-858c-45aa-867c-185ccf9d7e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1274/1274 [00:37<00:00, 33.75it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(dataset_md['test']):\n",
    "    # if row['title'] is None or row['title'] == '' or row['text'] is None or row['text'] == '':\n",
    "    #     print(row['content'])\n",
    "    #     continue\n",
    "    # print(row)\n",
    "    try:\n",
    "        perp, negloglike = compute_metrics(model, tokenizer, row['title'])\n",
    "        title_md.append({'title': row['title'], 'perplexity': perp, 'neg_log_likelihood': negloglike})\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        perp, negloglike = compute_metrics(model, tokenizer, row['text'])\n",
    "        content_md.append({'text': row['text'], 'perplexity': perp, 'neg_log_likelihood': negloglike})\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bfc1010-162d-48ed-a81f-67b1d3f5dc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1274, 1222)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_md), len(content_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67693c47-8d7b-4136-9b0c-03c19d19f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_mgpt_simple_romania_01 = {\"ro\": title_ro, \"md\": title_md}\n",
    "content_mgpt_simple_romania_01 = {\"ro\": content_ro, \"md\": content_md}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a75a0b7-fa7e-4676-8634-0aaed5d3b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"title_mgpt_simple_romania_01.json\", \"w\") as f:\n",
    "    json.dump(title_mgpt_simple_romania_01, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdebe6fc-bb6b-4fdb-af76-95807163265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"content_mgpt_simple_romania_01.json\", \"w\") as f:\n",
    "    json.dump(content_mgpt_simple_romania_01, f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
